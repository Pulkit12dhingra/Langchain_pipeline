{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0fdaf5",
   "metadata": {},
   "source": [
    "# In this notebook we'll build a simple RAG pipeline and explore ways of integrating chat history in the context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f3006",
   "metadata": {},
   "source": [
    "I have used `Ollama` to run the llm locally. The entire pipeline runs over the CPU.  \n",
    "[Setting up Ollama - Step-by-step guide](https://pulkit12dhingra.github.io/Blog/content/Setting_up_Ollama.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43186d",
   "metadata": {},
   "source": [
    "## First let's build a simple RAG pipeline\n",
    "[Building a RAG pipeline](https://pulkit12dhingra.github.io/Blog/content/Building_a_RAG_Pipeline_with_PDFs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86f78ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.11.18 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.11.18)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: altair==5.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (5.5.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (25.3.0)\n",
      "Requirement already satisfied: blinker==1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.9.0)\n",
      "Requirement already satisfied: cachetools==5.5.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (5.5.2)\n",
      "Requirement already satisfied: certifi==2025.4.26 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer==3.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: click==8.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (8.2.0)\n",
      "Requirement already satisfied: dataclasses-json==0.6.7 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.6.7)\n",
      "Requirement already satisfied: filelock==3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (3.18.0)\n",
      "Requirement already satisfied: frozenlist==1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (1.6.0)\n",
      "Requirement already satisfied: fsspec==2025.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2025.3.2)\n",
      "Requirement already satisfied: gitdb==4.0.12 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (4.0.12)\n",
      "Requirement already satisfied: GitPython==3.1.44 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (3.1.44)\n",
      "Requirement already satisfied: h11==0.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub==0.31.4 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (0.31.4)\n",
      "Requirement already satisfied: idna==3.10 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (3.10)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (3.1.6)\n",
      "Requirement already satisfied: joblib==1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (1.5.0)\n",
      "Requirement already satisfied: jsonpatch==1.33 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (2025.4.1)\n",
      "Requirement already satisfied: langchain==0.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (0.3.25)\n",
      "Requirement already satisfied: langchain-community==0.3.24 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (0.3.24)\n",
      "Requirement already satisfied: langchain-core==0.3.60 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (0.3.60)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.8 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.3.8)\n",
      "Requirement already satisfied: langsmith==0.3.42 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.3.42)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (3.0.2)\n",
      "Requirement already satisfied: marshmallow==3.26.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (3.26.1)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (6.4.4)\n",
      "Requirement already satisfied: mypy_extensions==1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (1.1.0)\n",
      "Requirement already satisfied: narwhals==1.40.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (1.40.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.2.6 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (2.2.6)\n",
      "Requirement already satisfied: orjson==3.10.18 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (3.10.18)\n",
      "Requirement already satisfied: packaging==24.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (2.2.3)\n",
      "Requirement already satisfied: pillow==11.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (11.2.1)\n",
      "Requirement already satisfied: propcache==0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.3.1)\n",
      "Requirement already satisfied: protobuf==6.31.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (6.31.0)\n",
      "Requirement already satisfied: pyarrow==20.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (20.0.0)\n",
      "Requirement already satisfied: pydantic==2.11.4 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (2.11.4)\n",
      "Requirement already satisfied: pydantic-settings==2.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (2.9.1)\n",
      "Requirement already satisfied: pydantic_core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (2.33.2)\n",
      "Requirement already satisfied: pydeck==0.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (0.9.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (1.1.0)\n",
      "Requirement already satisfied: pytz==2025.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (6.0.2)\n",
      "Requirement already satisfied: referencing==0.36.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.36.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (1.0.0)\n",
      "Requirement already satisfied: rpds-py==0.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (0.25.0)\n",
      "Requirement already satisfied: safetensors==0.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (1.15.3)\n",
      "Requirement already satisfied: sentence-transformers==4.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (4.1.0)\n",
      "Requirement already satisfied: setuptools==80.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (80.7.1)\n",
      "Requirement already satisfied: six==1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (1.17.0)\n",
      "Requirement already satisfied: smmap==5.0.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (5.0.2)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (1.3.1)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (2.0.41)\n",
      "Requirement already satisfied: streamlit==1.45.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (1.45.1)\n",
      "Requirement already satisfied: sympy==1.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (1.14.0)\n",
      "Requirement already satisfied: tenacity==9.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (9.1.2)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (3.6.0)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (0.21.1)\n",
      "Requirement already satisfied: toml==0.10.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (0.10.2)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (2.7.0)\n",
      "Requirement already satisfied: tornado==6.5 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (6.5)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (4.67.1)\n",
      "Requirement already satisfied: transformers==4.51.3 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (4.51.3)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (0.9.0)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 84)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 85)) (4.13.2)\n",
      "Requirement already satisfied: tzdata==2025.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 86)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 87)) (2.4.0)\n",
      "Requirement already satisfied: yarl==1.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 88)) (1.20.0)\n",
      "Requirement already satisfied: zstandard==0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 89)) (0.23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce17292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this step we'll read the text files from the 'data' directory and put them as a list\n",
    "# loading the text file conversation\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# use os module to go through the directory and load the text files\n",
    "import os \n",
    "# Store all loaded documents\n",
    "documents = []\n",
    "\n",
    "data_dir = \"data\"  # replace with your directory\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents.extend(loader.load())  # append loaded documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af907ef2",
   "metadata": {},
   "source": [
    "We can load a variety of documents using lanchains \n",
    "\n",
    "[Loading documents via langchain](https://pulkit12dhingra.github.io/Blog/content/LangChain_Document_Loaders.html)\n",
    "\n",
    "[official documentation](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c963e4",
   "metadata": {},
   "source": [
    "Now we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d4162fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the big text into smaller chunks \n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a35b885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding the text chunks\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537cbb5",
   "metadata": {},
   "source": [
    "Next we need to create a vectorstore (like a space) to save all the embeddings. It acts as a database to fetch the related contextual embeddings before prompting the LLM.\n",
    "\n",
    "[Vector Stores](https://python.langchain.com/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b313bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embedding_model)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54829b",
   "metadata": {},
   "source": [
    "Langchain supports a wide variety of models.\n",
    "\n",
    "[Official documentation on loading different models](https://python.langchain.com/docs/integrations/chat/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7ca51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# update this to load the different model\n",
    "\n",
    "# Initialize Ollama with the gemma3 model\n",
    "llm = Ollama(model=\"gemma3\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adc1b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and outlines different types of AI like Machine Learning (ML) and Deep Learning (DL). It also details Natural Language Processing (NLP) as the focus on enabling machines to understand and generate human language. Furthermore, it describes the Turing Test as a measure of a machine’s ability to mimic human intelligence, and highlights ethical concerns surrounding AI such as bias, job displacement, and lack of transparency. Finally, it introduces Explainable AI (XAI) as a method for making AI decisions more understandable and accountable.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "query = \"What is the summary of the text?\"\n",
    "response = rag_chain(query)\n",
    "\n",
    "print(\"Answer:\", response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26223966",
   "metadata": {},
   "source": [
    "# Extend the pipeline to maintain chat history and provide additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf6aa1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history aware chat\n",
    "\n",
    "# Import function to create a retriever that can use chat history to reformulate questions\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "# Import tools to construct prompt templates\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "\n",
    "# Define a prompt that instructs the LLM on how to reformulate questions\n",
    "retriever_prompt = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history,\"\n",
    "    \"formulate a standalone question which can be understood without the chat history.\"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "\n",
    "contextualize_q_prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", retriever_prompt), # Instructions to the model\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), # Past conversation messages\n",
    "        (\"human\", \"{input}\"), # Latest user question\n",
    "\n",
    "\n",
    "     ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(llm,\n",
    "                                                         retriever,\n",
    "                                                         contextualize_q_prompt # defined above\n",
    "                                                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This type of chain puts all retrieved documents into the context at once\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(\"chat_history\"), # Inserts the full chat history so the model understands the conversation flow\n",
    "        (\"human\", \"{input}\"), # Inserts the latest user question into the prompt\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define a PromptTemplate that explicitly includes \"context\" and \"input\" as variables.\n",
    "# This is used to feed retrieved documents and user questions into the LLM.\n",
    "stuff_prompt = PromptTemplate(\n",
    "\tinput_variables=[\"context\", \"input\"],\n",
    "\ttemplate=(\n",
    "\t\t\"Use the following pieces of context to answer the question at the end.\\n\"\n",
    "\t\t\"If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n\"\n",
    "\t\t\"{context}\\n\\nQuestion: {input}\\nHelpful Answer:\"\n",
    "\t)\n",
    ")\n",
    "# This chain feeds all retrieved context + the user query into the LLM using the above format.\n",
    "question_answer_chain = create_stuff_documents_chain(llm, stuff_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "653fedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# Combine the history-aware retriever and the QA chain into a full RAG pipeline\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1145e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "\n",
    "question1 = \"What is the summary of the text?\"\n",
    "message1= rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "632ae4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and introduces Machine Learning (ML) and Deep Learning (DL) as subsets of AI. It also details the Turing Test as a measure of a machine’s ability to mimic human intelligence, and Natural Language Processing (NLP) as the focus on enabling machines to understand and generate human language. Furthermore, it highlights ethical concerns surrounding AI such as bias, job displacement, and lack of transparency, and introduces Explainable AI (XAI) as a solution to improve trust and accountability in AI systems.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message1[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "571604a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question1),\n",
    "        AIMessage(content=message1[\"answer\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12f415c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the summary of the text?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and introduces Machine Learning (ML) and Deep Learning (DL) as subsets of AI. It also details the Turing Test as a measure of a machine’s ability to mimic human intelligence, and Natural Language Processing (NLP) as the focus on enabling machines to understand and generate human language. Furthermore, it highlights ethical concerns surrounding AI such as bias, job displacement, and lack of transparency, and introduces Explainable AI (XAI) as a solution to improve trust and accountability in AI systems.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fbfecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is the simulation of human intelligence in machines.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "second_question = \"provide the previous answer within 100 characters\"\n",
    "message2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(message2[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c201e",
   "metadata": {},
   "source": [
    "# Session-aware chat memory in a conversational RAG pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab107f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d2855e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve or create a chat history object for a given session ID\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Creates an in-memory dictionary store to hold chat histories for different users or sessions.\n",
    "# Ensures each session has a dedicated message history, using the session ID as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22222a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain, # The RAG chain created earlier\n",
    "    get_session_history, # Function that supplies chat history per session\n",
    "    input_messages_key=\"input\",  # Key in input dict for the user message\n",
    "    history_messages_key=\"chat_history\", # Used by LangChain to auto-track conversation\n",
    "    output_messages_key=\"answer\", # Key to extract the model's response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d7a905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text explains Artificial Intelligence (AI) as the simulation of human intelligence in machines. It differentiates between AI, Machine Learning (ML), and Deep Learning (DL), outlining their relationships. It then details the main types of AI: Narrow AI, General AI, and Super AI. Finally, it lists several real-world applications of AI, including virtual assistants, recommendation engines, self-driving cars, fraud detection, medical diagnosis, and language translation, and describes Natural Language Processing (NLP) as a field focused on enabling machines to understand and generate human language.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Summarize the text\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cd50c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='Summarize the text', additional_kwargs={}, response_metadata={}), AIMessage(content='The text describes several key areas within Artificial Intelligence (AI). AI is the broader concept of machines performing intelligent tasks. It encompasses various types, including Narrow AI (or Weak AI), which is specialized like recommendation engines and chatbots, and General AI, which would possess human-level intelligence. The text also discusses related fields like Machine Learning (ML) and Deep Learning (DL), which utilize neural networks. Furthermore, it highlights specific applications of AI such as virtual assistants, self-driving cars, fraud detection, medical diagnosis, and language translation, alongside the historical Turing Test, which assesses a machine’s ability to mimic human conversation.', additional_kwargs={}, response_metadata={}), HumanMessage(content='provide the previous answer within 100 characters', additional_kwargs={}, response_metadata={}), AIMessage(content='AI encompasses narrow, general, and super AI types, with ethical concerns like bias and job displacement.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Summarize the text', additional_kwargs={}, response_metadata={}), AIMessage(content='The text explains Artificial Intelligence (AI) as the simulation of human intelligence in machines. It differentiates between AI, Machine Learning (ML), and Deep Learning (DL), outlining their relationships. It then details the main types of AI: Narrow AI, General AI, and Super AI. Finally, it lists several real-world applications of AI, including virtual assistants, recommendation engines, self-driving cars, fraud detection, medical diagnosis, and language translation, and describes Natural Language Processing (NLP) as a field focused on enabling machines to understand and generate human language.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0ced7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Narrow, general, and super AI are the main types.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"provide the previous answer within 100 characters\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ad01f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Summarize the text\n",
      "\n",
      "AI: The text describes several key areas within Artificial Intelligence (AI). AI is the broader concept of machines performing intelligent tasks. It encompasses various types, including Narrow AI (or Weak AI), which is specialized like recommendation engines and chatbots, and General AI, which would possess human-level intelligence. The text also discusses related fields like Machine Learning (ML) and Deep Learning (DL), which utilize neural networks. Furthermore, it highlights specific applications of AI such as virtual assistants, self-driving cars, fraud detection, medical diagnosis, and language translation, alongside the historical Turing Test, which assesses a machine’s ability to mimic human conversation.\n",
      "\n",
      "User: provide the previous answer within 100 characters\n",
      "\n",
      "AI: AI encompasses narrow, general, and super AI types, with ethical concerns like bias and job displacement.\n",
      "\n",
      "User: Summarize the text\n",
      "\n",
      "AI: The text explains Artificial Intelligence (AI) as the simulation of human intelligence in machines. It differentiates between AI, Machine Learning (ML), and Deep Learning (DL), outlining their relationships. It then details the main types of AI: Narrow AI, General AI, and Super AI. Finally, it lists several real-world applications of AI, including virtual assistants, recommendation engines, self-driving cars, fraud detection, medical diagnosis, and language translation, and describes Natural Language Processing (NLP) as a field focused on enabling machines to understand and generate human language.\n",
      "\n",
      "User: provide the previous answer within 100 characters\n",
      "\n",
      "AI: Narrow, general, and super AI are the main types.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afd88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
