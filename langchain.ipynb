{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f78ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain_community in /opt/anaconda3/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.11.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (2.7.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce17292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the text file conversation\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# use os module to go through the directory and load the text files\n",
    "import os \n",
    "# Store all loaded documents\n",
    "documents = []\n",
    "\n",
    "data_dir = \"data\"  # replace with your directory\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        loader = TextLoader(file_path)\n",
    "        documents.extend(loader.load())  # append loaded documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4162fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the big text into smaller chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a35b885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/zw_bcxpn257g4khbkhrtn_vm0000gn/T/ipykernel_24230/2721590312.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# embedding the text chunks\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b313bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embedding=embedding_model)\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ca51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/zw_bcxpn257g4khbkhrtn_vm0000gn/T/ipykernel_24230/1557086837.py:6: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# update this to load the different model\n",
    "\n",
    "# Initialize Ollama with the gemma3 model\n",
    "llm = Ollama(model=\"gemma3\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc1b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cr/zw_bcxpn257g4khbkhrtn_vm0000gn/T/ipykernel_24230/2052742362.py:11: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = rag_chain(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and breaks it down into subsets like Machine Learning (ML) and Deep Learning (DL). Natural Language Processing (NLP) is a field within AI focused on enabling machines to understand and generate human language. The text also highlights ethical concerns surrounding AI, such as bias, job displacement, and privacy. Finally, it introduces Explainable AI (XAI) as a method for increasing trust and accountability in AI systems by providing understandable justifications for decisions.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "query = \"What is the summary of the text?\"\n",
    "response = rag_chain(query)\n",
    "\n",
    "print(\"Answer:\", response['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26223966",
   "metadata": {},
   "source": [
    "# Extend the pipeline to maintain chat history and provide additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6aa1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history aware chat\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "retriever_prompt = (\n",
    "    \"Given a chat history and the latest user question which might reference context in the chat history,\"\n",
    "    \"formulate a standalone question which can be understood without the chat history.\"\n",
    "    \"Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "\n",
    "contextualize_q_prompt  = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", retriever_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "\n",
    "\n",
    "     ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(llm,retriever,contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad1568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f1ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt that includes the required 'context' variable\n",
    "stuff_prompt = PromptTemplate(\n",
    "\tinput_variables=[\"context\", \"input\"],\n",
    "\ttemplate=(\n",
    "\t\t\"Use the following pieces of context to answer the question at the end.\\n\"\n",
    "\t\t\"If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n\"\n",
    "\t\t\"{context}\\n\\nQuestion: {input}\\nHelpful Answer:\"\n",
    "\t)\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, stuff_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "653fedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1145e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "chat_history = []\n",
    "\n",
    "question1 = \"What is the summary of the text?\"\n",
    "message1= rag_chain.invoke({\"input\": question1, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632ae4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and breaks it down into subsets like Machine Learning (ML) and Deep Learning (DL). It also details Natural Language Processing (NLP), which focuses on enabling machines to understand and generate human language. The Turing Test is presented as a benchmark for machine intelligence, and highlights ethical concerns surrounding AI, such as bias and lack of transparency. Finally, it introduces Explainable AI (XAI) as a method to improve trust and accountability in AI systems.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message1[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "571604a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question1),\n",
    "        AIMessage(content=message1[\"answer\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f415c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the summary of the text?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The text discusses several key concepts in the field of Artificial Intelligence (AI). It defines AI as the broader concept of machines performing intelligent tasks, and breaks it down into subsets like Machine Learning (ML) and Deep Learning (DL). It also details Natural Language Processing (NLP), which focuses on enabling machines to understand and generate human language. The Turing Test is presented as a benchmark for machine intelligence, and highlights ethical concerns surrounding AI, such as bias and lack of transparency. Finally, it introduces Explainable AI (XAI) as a method to improve trust and accountability in AI systems.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fbfecc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias, job loss, privacy, misuse, and lack of transparency are ethical AI concerns.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "second_question = \"provide the previous answer within 100 characters\"\n",
    "message2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(message2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ab107f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d2855e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46ed0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22222a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d7a905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text describes several key areas within Artificial Intelligence (AI). AI is the broader concept of machines performing intelligent tasks. It encompasses various types, including Narrow AI (or Weak AI), which is specialized like recommendation engines and chatbots, and General AI, which would possess human-level intelligence. The text also discusses related fields like Machine Learning (ML) and Deep Learning (DL), which utilize neural networks. Furthermore, it highlights specific applications of AI such as virtual assistants, self-driving cars, fraud detection, medical diagnosis, and language translation, alongside the historical Turing Test, which assesses a machine’s ability to mimic human conversation.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Summarize the text\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cd50c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='Summarize the text', additional_kwargs={}, response_metadata={}), AIMessage(content='The text describes several key areas within Artificial Intelligence (AI). AI is the broader concept of machines performing intelligent tasks. It encompasses various types, including Narrow AI (or Weak AI), which is specialized like recommendation engines and chatbots, and General AI, which would possess human-level intelligence. The text also discusses related fields like Machine Learning (ML) and Deep Learning (DL), which utilize neural networks. Furthermore, it highlights specific applications of AI such as virtual assistants, self-driving cars, fraud detection, medical diagnosis, and language translation, alongside the historical Turing Test, which assesses a machine’s ability to mimic human conversation.', additional_kwargs={}, response_metadata={})])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0ced7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI encompasses narrow, general, and super AI types, with ethical concerns like bias and job displacement.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"provide the previous answer within 100 characters\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ad01f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Summarize the text\n",
      "\n",
      "AI: The text describes several key areas within Artificial Intelligence (AI). AI is the broader concept of machines performing intelligent tasks. It encompasses various types, including Narrow AI (or Weak AI), which is specialized like recommendation engines and chatbots, and General AI, which would possess human-level intelligence. The text also discusses related fields like Machine Learning (ML) and Deep Learning (DL), which utilize neural networks. Furthermore, it highlights specific applications of AI such as virtual assistants, self-driving cars, fraud detection, medical diagnosis, and language translation, alongside the historical Turing Test, which assesses a machine’s ability to mimic human conversation.\n",
      "\n",
      "User: provide the previous answer within 100 characters\n",
      "\n",
      "AI: AI encompasses narrow, general, and super AI types, with ethical concerns like bias and job displacement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afd88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
